_target_: src.models.transformer_encoder_model.TransformerEncoderModel
n_layers: 1
dim_feedforward: 48
token_dim: 64
activation: gelu
nhead: 4
